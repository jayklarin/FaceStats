{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ca32b0",
   "metadata": {},
   "source": [
    "# 04 — Attractiveness Model Training (FaceStats v4)\n",
    "Train the AttractivenessRegressor on CLIP embeddings using synthetic, deterministic labels (hash-based) until real labels are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc9b58",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- Load embeddings from `data/processed/embeddings_clip.parquet`\n",
    "- Derive `id` from filename stem\n",
    "- Generate deterministic synthetic labels (hash of `id`, scaled to [0, 1]) for placeholder training\n",
    "- Split train/validation, train the MLP regressor, report losses\n",
    "- Save checkpoint to `models/attractiveness_regressor.pt`\n",
    "- Swap in real labels later by replacing the synthetic-label cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e4d61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /Users/jayklarin/__DI/Repositories/FaceStats\n",
      "src path added: /Users/jayklarin/__DI/Repositories/FaceStats/src\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure cwd is project root for imports/paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "SRC_PATH = PROJECT_ROOT / \"src\"\n",
    "if str(SRC_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_PATH))\n",
    "\n",
    "print(\"cwd:\", Path.cwd())\n",
    "print(\"src path added:\", SRC_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f334df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11ad612f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Union\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from models.attractiveness_model import AttractivenessRegressor\n",
    "\n",
    "# Paths (v4)\n",
    "EMBED_PATH = Path(\"data/processed/embeddings_clip.parquet\")\n",
    "OUTPUT_MODEL_PATH = Path(\"models/attractiveness_regressor.pt\")\n",
    "\n",
    "# Training hyperparameters\n",
    "RANDOM_SEED = 42\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4\n",
    "VAL_FRACTION = 0.2\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa42f9",
   "metadata": {},
   "source": [
    "## Load embeddings\n",
    "Reads CLIP embeddings parquet, validates columns, and derives `id` from filename stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8031960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌───────────────────────┬─────────────────────────────────┬───────────────────┐\n",
      "│ filename              ┆ embedding                       ┆ id                │\n",
      "│ ---                   ┆ ---                             ┆ ---               │\n",
      "│ str                   ┆ list[f64]                       ┆ str               │\n",
      "╞═══════════════════════╪═════════════════════════════════╪═══════════════════╡\n",
      "│ SFHQ_pt4_00000208.jpg ┆ [0.050459, -0.042498, … -0.011… ┆ SFHQ_pt4_00000208 │\n",
      "│ SFHQ_pt4_00002966.jpg ┆ [-0.00345, -0.025553, … -0.002… ┆ SFHQ_pt4_00002966 │\n",
      "│ SFHQ_pt4_00003463.jpg ┆ [0.049876, -0.015998, … 0.0299… ┆ SFHQ_pt4_00003463 │\n",
      "│ SFHQ_pt4_00002219.jpg ┆ [0.050927, -0.002582, … 0.0140… ┆ SFHQ_pt4_00002219 │\n",
      "│ SFHQ_pt4_00003112.jpg ┆ [0.021666, -0.005994, … -0.009… ┆ SFHQ_pt4_00003112 │\n",
      "└───────────────────────┴─────────────────────────────────┴───────────────────┘\n",
      "Loaded 80 embeddings\n"
     ]
    }
   ],
   "source": [
    "if not EMBED_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing embeddings parquet: {EMBED_PATH}\")\n",
    "\n",
    "embeddings_df = pl.read_parquet(EMBED_PATH)\n",
    "expected_cols = {\"filename\", \"embedding\"}\n",
    "missing = expected_cols - set(embeddings_df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Embeddings parquet missing columns: {missing}\")\n",
    "\n",
    "embeddings_df = embeddings_df.with_columns(\n",
    "    pl.col(\"filename\").map_elements(lambda x: Path(x).stem).alias(\"id\")\n",
    ")\n",
    "\n",
    "print(embeddings_df.head())\n",
    "print(f\"Loaded {len(embeddings_df)} embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f27b46",
   "metadata": {},
   "source": [
    "## Synthetic labels (deterministic hash)\n",
    "Creates placeholder labels by hashing the `id` and scaling to [0, 1]. Replace this cell when real labels are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2252b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌───────────────────┬──────────────────────┐\n",
      "│ id                ┆ attractiveness_label │\n",
      "│ ---               ┆ ---                  │\n",
      "│ str               ┆ f64                  │\n",
      "╞═══════════════════╪══════════════════════╡\n",
      "│ SFHQ_pt4_00000208 ┆ 0.496663             │\n",
      "│ SFHQ_pt4_00002966 ┆ 0.044135             │\n",
      "│ SFHQ_pt4_00003463 ┆ 0.421839             │\n",
      "│ SFHQ_pt4_00002219 ┆ 0.18107              │\n",
      "│ SFHQ_pt4_00003112 ┆ 0.864885             │\n",
      "└───────────────────┴──────────────────────┘\n",
      "Label stats: 0.011262744286187338 0.970123531559696\n"
     ]
    }
   ],
   "source": [
    "def hash_to_unit_float(text: str) -> float:\n",
    "    h = hashlib.sha256(text.encode(\"utf-8\")).hexdigest()\n",
    "    as_int = int(h, 16)\n",
    "    return as_int / ((1 << 256) - 1)\n",
    "\n",
    "embeddings_df = embeddings_df.with_columns(\n",
    "    pl.col(\"id\").map_elements(hash_to_unit_float).alias(\"attractiveness_label\")\n",
    ")\n",
    "\n",
    "print(embeddings_df.select([\"id\", \"attractiveness_label\"]).head())\n",
    "print(\"Label stats:\", embeddings_df[\"attractiveness_label\"].min(), embeddings_df[\"attractiveness_label\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab79170",
   "metadata": {},
   "source": [
    "## Train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fbf19a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 64 | Val size: 16\n"
     ]
    }
   ],
   "source": [
    "n = len(embeddings_df)\n",
    "indices = np.arange(n)\n",
    "np.random.shuffle(indices)\n",
    "split = int(n * (1 - VAL_FRACTION))\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "train_df = embeddings_df[train_idx.tolist()]\n",
    "val_df = embeddings_df[val_idx.tolist()]\n",
    "\n",
    "print(f\"Train size: {len(train_df)} | Val size: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60184e44",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd06655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, df: pl.DataFrame):\n",
    "        self.X = df[\"embedding\"].to_list()\n",
    "        self.y = df[\"attractiveness_label\"].to_list()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.X[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.y[idx], dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "train_ds = EmbeddingDataset(train_df)\n",
    "val_ds = EmbeddingDataset(val_df)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5573f",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d3026c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttractivenessRegressor(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = len(train_df[\"embedding\"][0]) if len(train_df) else 0\n",
    "if embedding_dim == 0:\n",
    "    raise ValueError(\"Embedding dimension could not be determined.\")\n",
    "\n",
    "model = AttractivenessRegressor(input_dim=embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce98d5",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fedd8085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.3601 | val_loss=0.4366\n",
      "Epoch 02 | train_loss=0.3447 | val_loss=0.4191\n",
      "Epoch 03 | train_loss=0.3305 | val_loss=0.4016\n",
      "Epoch 04 | train_loss=0.3151 | val_loss=0.3847\n",
      "Epoch 05 | train_loss=0.3014 | val_loss=0.3690\n"
     ]
    }
   ],
   "source": [
    "def run_epoch(dl, model, optimizer=None):\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    for X, y in dl:\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X).squeeze()\n",
    "            loss = loss_fn(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                preds = model(X).squeeze()\n",
    "                loss = loss_fn(preds, y)\n",
    "        total_loss += loss.item() * len(X)\n",
    "        count += len(X)\n",
    "    return total_loss / max(count, 1)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = run_epoch(train_dl, model, optimizer)\n",
    "    val_loss = run_epoch(val_dl, model, optimizer=None)\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4798b",
   "metadata": {},
   "source": [
    "## Save model\n",
    "Saves state_dict to `models/attractiveness_regressor.pt` (creates the directory if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5936038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to models/attractiveness_regressor.pt\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), OUTPUT_MODEL_PATH)\n",
    "print(f\"Saved model to {OUTPUT_MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b0d7e",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Replace the synthetic label cell with real labels when available, then retrain and resave.\n",
    "- Adjust hyperparameters (epochs, LR, hidden size) in the imports/config cell as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facestats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
