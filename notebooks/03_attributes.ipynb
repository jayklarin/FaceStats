{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56140142",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "classDef notebook fill:#5c7fa6,stroke:#3f5a7b,color:#f2f6fb,font-weight:bold;\n",
    "classDef python fill:#9a80b8,stroke:#6d5789,color:#f7f3fb,font-weight:bold;\n",
    "classDef tools fill:#e9c48a,stroke:#b58950,color:#2d1c05;\n",
    "classDef methods fill:#8cc7ab,stroke:#5e9475,color:#0f2f1f;\n",
    "\n",
    "N03[\"03_attributes.ipynb\"]:::notebook\n",
    "\n",
    "N03 --> A1[\"face_attributes.py\"]:::python\n",
    "\n",
    "A1 --> T3[\"Tools:<br>joblib<br>numpy<br>Pillow\"]:::tools\n",
    "\n",
    "T3 --> M3[\"Methods:<br>get_embedding()<br>infer_attributes()\"]:::methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d0ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /Users/jayklarin/__DI/Repositories/FaceStats\n",
      "src path added: /Users/jayklarin/__DI/Repositories/FaceStats/src\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# 1) Set notebook working directory = FaceStats project root\n",
    "PROJECT_ROOT = \"/Users/jayklarin/__DI/Repositories/FaceStats\"\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "# 2) Add src/ folder to Python PATH\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "\n",
    "print(\"src path added:\", SRC_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c43166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "CLIP model will now load onto MPS.\n",
      "CLIP processor outputs will now run on MPS.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "# Select device: MPS if available\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --- Wrap CLIP model loading ---\n",
    "_original_clip_from_pretrained = CLIPModel.from_pretrained\n",
    "\n",
    "def _mps_clip_from_pretrained(*args, **kwargs):\n",
    "    model = _original_clip_from_pretrained(*args, **kwargs)\n",
    "    return model.to(device)\n",
    "\n",
    "CLIPModel.from_pretrained = _mps_clip_from_pretrained\n",
    "print(\"CLIP model will now load onto MPS.\")\n",
    "\n",
    "\n",
    "# --- Wrap CLIPProcessor output only (no recursion risk) ---\n",
    "_original_processor_from_pretrained = CLIPProcessor.from_pretrained\n",
    "\n",
    "class MPSProcessorWrapper:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.processor, name)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        out = self.processor(*args, **kwargs)\n",
    "        # Move tensors in the output batch to MPS\n",
    "        for k, v in out.items():\n",
    "            if torch.is_tensor(v):\n",
    "                out[k] = v.to(device)\n",
    "        return out\n",
    "\n",
    "def _mps_processor_from_pretrained(*args, **kwargs):\n",
    "    processor = _original_processor_from_pretrained(*args, **kwargs)\n",
    "    return MPSProcessorWrapper(processor)\n",
    "\n",
    "CLIPProcessor.from_pretrained = _mps_processor_from_pretrained\n",
    "print(\"CLIP processor outputs will now run on MPS.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156e6f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌───────────────────────┬──────┬─────────┬───────────┐\n",
      "│ filename              ┆ age  ┆ gender  ┆ ethnicity │\n",
      "│ ---                   ┆ ---  ┆ ---     ┆ ---       │\n",
      "│ str                   ┆ null ┆ str     ┆ str       │\n",
      "╞═══════════════════════╪══════╪═════════╪═══════════╡\n",
      "│ SFHQ_pt4_00000001.jpg ┆ null ┆ unknown ┆ unknown   │\n",
      "│ SFHQ_pt4_00000002.jpg ┆ null ┆ unknown ┆ unknown   │\n",
      "│ SFHQ_pt4_00000003.jpg ┆ null ┆ unknown ┆ unknown   │\n",
      "│ SFHQ_pt4_00000004.jpg ┆ null ┆ male    ┆ unknown   │\n",
      "│ SFHQ_pt4_00000005.jpg ┆ null ┆ male    ┆ unknown   │\n",
      "└───────────────────────┴──────┴─────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import src.attributes.face_attributes as fa\n",
    "\n",
    "INPUT_DIR = \"data/processed/preproc\"\n",
    "OUTPUT_FILE = \"data/processed/metadata/attributes.parquet\"\n",
    "\n",
    "os.makedirs(\"data/processed/metadata\", exist_ok=True)\n",
    "\n",
    "\n",
    "def infer_attributes_safe(image_path):\n",
    "    emb = fa.get_embedding(image_path)          # shape (N,)\n",
    "    emb = np.array(emb).reshape(1, -1)\n",
    "\n",
    "    gender_pred = fa.GENDER_MODEL.predict(emb)[0]\n",
    "    ethnicity_pred = fa.ETHNICITY_MODEL.predict(emb)[0]\n",
    "\n",
    "    def resolve(pred, classes):\n",
    "        if isinstance(pred, (int, np.integer)):\n",
    "            return classes[pred]\n",
    "        return str(pred)\n",
    "\n",
    "    return {\n",
    "        \"gender\": resolve(gender_pred, fa.GENDER_CLASSES),\n",
    "        \"ethnicity\": resolve(ethnicity_pred, fa.ETHNICITY_CLASSES),\n",
    "        \"age\": None,\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "\n",
    "for fname in sorted(os.listdir(INPUT_DIR)):\n",
    "    if not fname.lower().endswith(\".jpg\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(INPUT_DIR, fname)\n",
    "    attrs = infer_attributes_safe(path)\n",
    "\n",
    "    rows.append({\n",
    "        \"filename\": fname,\n",
    "        \"age\": attrs.get(\"age\"),\n",
    "        \"gender\": attrs[\"gender\"],\n",
    "        \"ethnicity\": attrs[\"ethnicity\"],\n",
    "    })\n",
    "\n",
    "if not rows:\n",
    "    raise SystemExit(\"No rows produced; check input images.\")\n",
    "\n",
    "df = pl.DataFrame(rows)\n",
    "df.write_parquet(OUTPUT_FILE)\n",
    "\n",
    "print(df.head())\n",
    "# 25 - 35 minutes on cpu\n",
    "# 10 - 15 minutes on mps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d170b64",
   "metadata": {},
   "source": [
    "### Step 3 — Load FairFace Label Structure\n",
    "\n",
    "We avoid HuggingFace entirely and use the FairFace test output file to recover:\n",
    "\n",
    "- Race class order (7-class)\n",
    "- Race class order (4-class)\n",
    "- Gender class order\n",
    "- Age bucket order\n",
    "\n",
    "These are needed to build a lightweight local classifier that maps InsightFace embeddings → attribute predictions.\n",
    "\n",
    "This step ensures all later attributes (such as ethnicity filters in composites) behave correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3cc1edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['white',\n",
       "  'black',\n",
       "  'latino/hispanic',\n",
       "  'east asian',\n",
       "  'southeast asian',\n",
       "  'indian',\n",
       "  'middle eastern'],\n",
       " ['white', 'black', 'asian', 'indian'],\n",
       " ['male', 'female'],\n",
       " ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70+'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "TEST_CSV = \"data/raw/fairface/test_outputs.csv\"\n",
    "\n",
    "df = pl.read_csv(TEST_CSV)\n",
    "\n",
    "# Extract the first row and parse arrays\n",
    "def parse_array(s):\n",
    "    s = s.strip().lstrip(\"[\").rstrip(\"]\")\n",
    "    return [float(x) for x in s.split(\",\")]\n",
    "\n",
    "row = df.row(0)\n",
    "\n",
    "race7 = parse_array(row[df.columns.index(\"race_scores_fair_7\")])\n",
    "race4 = parse_array(row[df.columns.index(\"race_scores_fair_4\")])\n",
    "gender = parse_array(row[df.columns.index(\"gender_scores_fair\")])\n",
    "age = parse_array(row[df.columns.index(\"age_scores_fair\")])\n",
    "\n",
    "race7_labels = [\n",
    "    \"white\", \"black\", \"latino/hispanic\",\n",
    "    \"east asian\", \"southeast asian\",\n",
    "    \"indian\", \"middle eastern\"\n",
    "]\n",
    "\n",
    "race4_labels = [\"white\", \"black\", \"asian\", \"indian\"]\n",
    "\n",
    "gender_labels = [\"male\", \"female\"]\n",
    "\n",
    "age_labels = [\n",
    "    \"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\",\n",
    "    \"40-49\", \"50-59\", \"60-69\", \"70+\"\n",
    "]\n",
    "\n",
    "race7_labels, race4_labels, gender_labels, age_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c1467",
   "metadata": {},
   "source": [
    "### Step 4 — Validate Attribute Results\n",
    "\n",
    "Now that we have:\n",
    "\n",
    "- InsightFace age + gender estimations  \n",
    "- FairFace race/gender/age **label order**  \n",
    "- Clean attribute parquet from Step 2  \n",
    "\n",
    "We perform a quick validation:\n",
    "\n",
    "1. Load the first few faces  \n",
    "2. Show their raw InsightFace predictions  \n",
    "3. Confirm ethnicity is still `\"unknown\"` (expected)  \n",
    "4. Confirm age values look reasonable (0–100)  \n",
    "5. Confirm gender values match `male` / `female`  \n",
    "6. Print the FairFace label order for final confirmation  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe0ccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded attributes: (31396, 4)\n",
      "\n",
      "Sample of attribute predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SFHQ_pt4_00000001.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SFHQ_pt4_00000002.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SFHQ_pt4_00000003.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SFHQ_pt4_00000004.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>male</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SFHQ_pt4_00000005.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>male</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename   age   gender ethnicity\n",
       "0  SFHQ_pt4_00000001.jpg  None  unknown   unknown\n",
       "1  SFHQ_pt4_00000002.jpg  None  unknown   unknown\n",
       "2  SFHQ_pt4_00000003.jpg  None  unknown   unknown\n",
       "3  SFHQ_pt4_00000004.jpg  None     male   unknown\n",
       "4  SFHQ_pt4_00000005.jpg  None     male   unknown"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age range (min, max):\n",
      "None None\n",
      "\n",
      "Gender distribution:\n",
      "shape: (3, 2)\n",
      "┌─────────┬───────┐\n",
      "│ gender  ┆ count │\n",
      "│ ---     ┆ ---   │\n",
      "│ str     ┆ u32   │\n",
      "╞═════════╪═══════╡\n",
      "│ male    ┆ 4694  │\n",
      "│ female  ┆ 4061  │\n",
      "│ unknown ┆ 22641 │\n",
      "└─────────┴───────┘\n",
      "\n",
      "Ethnicity distribution:\n",
      "shape: (7, 2)\n",
      "┌─────────────────────────┬───────┐\n",
      "│ ethnicity               ┆ count │\n",
      "│ ---                     ┆ ---   │\n",
      "│ str                     ┆ u32   │\n",
      "╞═════════════════════════╪═══════╡\n",
      "│ black                   ┆ 761   │\n",
      "│ indian                  ┆ 178   │\n",
      "│ latino/hispanic         ┆ 835   │\n",
      "│ east_or_southeast_asian ┆ 646   │\n",
      "│ white                   ┆ 3880  │\n",
      "│ middle_eastern          ┆ 242   │\n",
      "│ unknown                 ┆ 24854 │\n",
      "└─────────────────────────┴───────┘\n",
      "\n",
      "FairFace Label Structure:\n",
      "race7: ['white', 'black', 'latino/hispanic', 'east asian', 'southeast asian', 'indian', 'middle eastern']\n",
      "race4: ['white', 'black', 'asian', 'indian']\n",
      "gender: ['male', 'female']\n",
      "age: ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70+']\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from attributes.face_attributes import infer_attributes\n",
    "\n",
    "# Load the attributes we already computed earlier\n",
    "ATTR_FILE = \"data/processed/metadata/attributes.parquet\"\n",
    "df_attr = pl.read_parquet(ATTR_FILE)\n",
    "\n",
    "print(\"Loaded attributes:\", df_attr.shape)\n",
    "\n",
    "# --- Show a sample of 5 records ---\n",
    "print(\"\\nSample of attribute predictions:\")\n",
    "display(df_attr.head().to_pandas())\n",
    "\n",
    "# --- Validate age range ---\n",
    "print(\"\\nAge range (min, max):\")\n",
    "print(df_attr[\"age\"].min(), df_attr[\"age\"].max())\n",
    "\n",
    "# --- Validate gender distribution ---\n",
    "print(\"\\nGender distribution:\")\n",
    "print(df_attr[\"gender\"].value_counts())\n",
    "\n",
    "# --- Validate ethnicity (should be mostly 'unknown' for now) ---\n",
    "print(\"\\nEthnicity distribution:\")\n",
    "print(df_attr[\"ethnicity\"].value_counts())\n",
    "\n",
    "# --- Load label structure from Step 3 ---\n",
    "LABELS = {\n",
    "    \"race7\": [\n",
    "        \"white\", \"black\", \"latino/hispanic\",\n",
    "        \"east asian\", \"southeast asian\",\n",
    "        \"indian\", \"middle eastern\"\n",
    "    ],\n",
    "    \"race4\": [\"white\", \"black\", \"asian\", \"indian\"],\n",
    "    \"gender\": [\"male\", \"female\"],\n",
    "    \"age\": [\n",
    "        \"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\",\n",
    "        \"40-49\", \"50-59\", \"60-69\", \"70+\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\nFairFace Label Structure:\")\n",
    "for k,v in LABELS.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febec7f6",
   "metadata": {},
   "source": [
    "### Step 5 — Train FairFace Attribute Classifier (InsightFace Embeddings)\n",
    "\n",
    "In this step, we merge three data sources:\n",
    "\n",
    "1. **InsightFace / CLIP Embeddings**  \n",
    "   `data/processed/embeddings/embeddings_clip.parquet`  \n",
    "   Contains:  \n",
    "   - `filename`  \n",
    "   - `embedding` (512-D InsightFace vector)\n",
    "\n",
    "2. **Attributes extracted by face_attributes.py**  \n",
    "   `data/processed/metadata/attributes.parquet`  \n",
    "   Contains:  \n",
    "   - age  \n",
    "   - gender  \n",
    "   - ethnicity\n",
    "\n",
    "3. **FairFace class label structure**  \n",
    "   `data/processed/metadata/fairface_label_structure.parquet`  \n",
    "   Contains:  \n",
    "   - race7 labels  \n",
    "   - race4 labels  \n",
    "   - gender labels  \n",
    "   - age bucket labels  \n",
    "\n",
    "We join on `filename` and prepare a combined training dataset.  \n",
    "This merged dataset is used to train lightweight auxiliary classifiers  \n",
    "(e.g., ethnicity classifier) for downstream composite filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9bec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "Attributes: (31396, 4)\n",
      "Embeddings: (31396, 2)\n",
      "Labels: (1, 4)\n",
      "\n",
      "Merged dataset shape: (31396, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>filename</th><th>embedding</th><th>age</th><th>gender</th><th>ethnicity</th></tr><tr><td>str</td><td>list[f64]</td><td>null</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;SFHQ_pt4_00000001.jpg&quot;</td><td>[0.04294, -0.029913, … -0.003311]</td><td>null</td><td>&quot;unknown&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00000002.jpg&quot;</td><td>[0.075275, -0.025003, … 0.02347]</td><td>null</td><td>&quot;unknown&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00000003.jpg&quot;</td><td>[0.029614, -0.052664, … -0.014799]</td><td>null</td><td>&quot;unknown&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00000004.jpg&quot;</td><td>[0.030962, -0.03723, … 0.008554]</td><td>null</td><td>&quot;male&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00000005.jpg&quot;</td><td>[0.036542, -0.022052, … -0.019474]</td><td>null</td><td>&quot;male&quot;</td><td>&quot;unknown&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌───────────────────────┬─────────────────────────────────┬──────┬─────────┬───────────┐\n",
       "│ filename              ┆ embedding                       ┆ age  ┆ gender  ┆ ethnicity │\n",
       "│ ---                   ┆ ---                             ┆ ---  ┆ ---     ┆ ---       │\n",
       "│ str                   ┆ list[f64]                       ┆ null ┆ str     ┆ str       │\n",
       "╞═══════════════════════╪═════════════════════════════════╪══════╪═════════╪═══════════╡\n",
       "│ SFHQ_pt4_00000001.jpg ┆ [0.04294, -0.029913, … -0.0033… ┆ null ┆ unknown ┆ unknown   │\n",
       "│ SFHQ_pt4_00000002.jpg ┆ [0.075275, -0.025003, … 0.0234… ┆ null ┆ unknown ┆ unknown   │\n",
       "│ SFHQ_pt4_00000003.jpg ┆ [0.029614, -0.052664, … -0.014… ┆ null ┆ unknown ┆ unknown   │\n",
       "│ SFHQ_pt4_00000004.jpg ┆ [0.030962, -0.03723, … 0.00855… ┆ null ┆ male    ┆ unknown   │\n",
       "│ SFHQ_pt4_00000005.jpg ┆ [0.036542, -0.022052, … -0.019… ┆ null ┆ male    ┆ unknown   │\n",
       "└───────────────────────┴─────────────────────────────────┴──────┴─────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "ATTR = \"data/processed/metadata/attributes.parquet\"\n",
    "EMB  = \"data/processed/embeddings/embeddings_clip.parquet\"\n",
    "LABELS = \"data/processed/metadata/fairface_label_structure.parquet\"\n",
    "\n",
    "# Load all three sources\n",
    "df_attr = pl.read_parquet(ATTR)\n",
    "df_emb  = pl.read_parquet(EMB)\n",
    "df_lab  = pl.read_parquet(LABELS)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"Attributes:\", df_attr.shape)\n",
    "print(\"Embeddings:\", df_emb.shape)\n",
    "print(\"Labels:\", df_lab.shape)\n",
    "\n",
    "# === Merge: embeddings + attributes ===\n",
    "df = (\n",
    "    df_emb.join(df_attr, on=\"filename\", how=\"inner\")\n",
    ")\n",
    "\n",
    "print(\"\\nMerged dataset shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41e86d",
   "metadata": {},
   "source": [
    "### Step 7 — Merge Manual Gender/Ethnicity Labels\n",
    "\n",
    "We now combine three sources:\n",
    "\n",
    "1. **Attributes**  \n",
    "   - Age estimates  \n",
    "   - Existing metadata  \n",
    "   - (`data/processed/metadata/attributes.parquet`)\n",
    "\n",
    "2. **Embeddings (CLIP)**  \n",
    "   - 1280-D embeddings for each image  \n",
    "   - (`data/processed/embeddings/embeddings_clip.parquet`)\n",
    "\n",
    "3. **Manual Labels (new!)**  \n",
    "   - Gender + Ethnicity assigned via the Streamlit labeling app  \n",
    "   - (`data/processed/metadata/manual_labels.csv`)\n",
    "\n",
    "This merged dataset will be the foundation for training:\n",
    "- Gender classifier  \n",
    "- 6-class Ethnicity classifier  \n",
    "- Any future supervised models\n",
    "\n",
    "The merged file will be stored as:\n",
    "\n",
    "`data/processed/metadata/attributes_with_manual.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1376e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto attributes: (31396, 4)\n",
      "Manual labels: (200, 3)\n",
      "Clean attributes: (31396, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>filename</th><th>age</th><th>gender_final</th><th>ethnicity_final</th></tr><tr><td>str</td><td>null</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;SFHQ_pt4_00000001.jpg&quot;</td><td>null</td><td>&quot;unknown&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00000002.jpg&quot;</td><td>null</td><td>&quot;unknown&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00000003.jpg&quot;</td><td>null</td><td>&quot;unknown&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00000004.jpg&quot;</td><td>null</td><td>&quot;male&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00000005.jpg&quot;</td><td>null</td><td>&quot;male&quot;</td><td>&quot;unknown&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────────────────┬──────┬──────────────┬─────────────────┐\n",
       "│ filename              ┆ age  ┆ gender_final ┆ ethnicity_final │\n",
       "│ ---                   ┆ ---  ┆ ---          ┆ ---             │\n",
       "│ str                   ┆ null ┆ str          ┆ str             │\n",
       "╞═══════════════════════╪══════╪══════════════╪═════════════════╡\n",
       "│ SFHQ_pt4_00000001.jpg ┆ null ┆ unknown      ┆ unknown         │\n",
       "│ SFHQ_pt4_00000002.jpg ┆ null ┆ unknown      ┆ unknown         │\n",
       "│ SFHQ_pt4_00000003.jpg ┆ null ┆ unknown      ┆ unknown         │\n",
       "│ SFHQ_pt4_00000004.jpg ┆ null ┆ male         ┆ unknown         │\n",
       "│ SFHQ_pt4_00000005.jpg ┆ null ┆ male         ┆ unknown         │\n",
       "└───────────────────────┴──────┴──────────────┴─────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load auto + manual\n",
    "attr = pl.read_parquet(\"data/processed/metadata/attributes.parquet\")\n",
    "ml   = pl.read_csv(\"data/processed/metadata/manual_labels.csv\")\n",
    "\n",
    "print(\"Auto attributes:\", attr.shape)\n",
    "print(\"Manual labels:\", ml.shape)\n",
    "\n",
    "# Merge manual labels\n",
    "merged = (\n",
    "    attr\n",
    "    .join(ml, on=\"filename\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Final combined labels\n",
    "merged = merged.with_columns([\n",
    "\n",
    "    # Final gender\n",
    "    pl.coalesce([\n",
    "        pl.col(\"gender_right\"),     # manual (new)\n",
    "        pl.col(\"gender\"),           # auto fallback\n",
    "        pl.lit(\"unknown\")\n",
    "    ]).alias(\"gender_final\"),\n",
    "\n",
    "    # Final ethnicity\n",
    "    pl.coalesce([\n",
    "        pl.col(\"ethnicity_right\"),  # manual (new)\n",
    "        pl.col(\"ethnicity\"),        # auto fallback\n",
    "        pl.lit(\"unknown\")\n",
    "    ]).alias(\"ethnicity_final\"),\n",
    "\n",
    "])\n",
    "\n",
    "clean = merged.select([\n",
    "    \"filename\",\n",
    "    \"age\",\n",
    "    \"gender_final\",\n",
    "    \"ethnicity_final\",\n",
    "])\n",
    "\n",
    "print(\"Clean attributes:\", clean.shape)\n",
    "clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fde28e",
   "metadata": {},
   "source": [
    "## Save attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789f54ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → data/processed/metadata/attributes_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "OUT = \"data/processed/metadata/attributes_clean.parquet\"\n",
    "clean.write_parquet(OUT)\n",
    "print(\"Saved →\", OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4dce03",
   "metadata": {},
   "source": [
    "### Step 8 — Train Gender & Ethnicity Classifiers (Using Clean Labels)\n",
    "\n",
    "Now that we have **attributes_clean.parquet** with corrected gender + ethnicity:\n",
    "\n",
    "- `gender_final`  \n",
    "- `ethnicity_final`  \n",
    "\n",
    "We can train two classifiers:\n",
    "\n",
    "1. **Gender classifier**  \n",
    "2. **Ethnicity classifier**\n",
    "\n",
    "Both use the **CLIP embeddings** as input (64-D vectors from `embeddings_clip.parquet`).\n",
    "\n",
    "This produces:\n",
    "\n",
    "- `models/gender_clf.pkl`\n",
    "- `models/ethnicity_clf.pkl`\n",
    "\n",
    "These models will be used throughout the rest of the FaceStats pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cfbf127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes: (31396, 4)\n",
      "Embeddings: (31396, 2)\n",
      "Merged: (31396, 5)\n",
      "Unique genders: {'unknown', 'female', 'male'}\n",
      "Unique ethnicities: {'black', 'indian', 'east_or_southeast_asian', 'unknown', 'white', 'middle_eastern', 'latino/hispanic'}\n",
      "Training gender classifier…\n",
      "Training ethnicity classifier…\n",
      "\n",
      "Saved models:\n",
      "  → src/models/gender_clf.pkl\n",
      "  → src/models/ethnicity_clf.pkl\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# LOAD CLEAN LABELS + EMBEDDINGS\n",
    "# ------------------------------------------------------------\n",
    "ATTR = \"data/processed/metadata/attributes_clean.parquet\"\n",
    "EMB  = \"data/processed/embeddings/embeddings_clip.parquet\"\n",
    "\n",
    "df_attr = pl.read_parquet(ATTR)\n",
    "df_emb  = pl.read_parquet(EMB)\n",
    "\n",
    "print(\"Attributes:\", df_attr.shape)\n",
    "print(\"Embeddings:\", df_emb.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# MERGE\n",
    "# ------------------------------------------------------------\n",
    "df = (\n",
    "    df_emb\n",
    "    .join(df_attr, on=\"filename\", how=\"inner\")\n",
    ")\n",
    "\n",
    "print(\"Merged:\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# PREPARE INPUT MATRICES\n",
    "# ------------------------------------------------------------\n",
    "X = np.vstack(df[\"embedding\"].to_list())\n",
    "\n",
    "gender_y    = df[\"gender_final\"].to_list()\n",
    "ethnicity_y = df[\"ethnicity_final\"].to_list()\n",
    "\n",
    "print(\"Unique genders:\", set(gender_y))\n",
    "print(\"Unique ethnicities:\", set(ethnicity_y))\n",
    "\n",
    "# Must have ≥ 2 classes to train\n",
    "assert len(set(gender_y)) >= 2, \"Not enough gender classes!\"\n",
    "assert len(set(ethnicity_y)) >= 2, \"Not enough ethnicity classes!\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# PIPELINES\n",
    "# ------------------------------------------------------------\n",
    "def make_pipeline():\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=500))\n",
    "    ])\n",
    "\n",
    "gender_clf    = make_pipeline()\n",
    "ethnicity_clf = make_pipeline()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# TRAIN\n",
    "# ------------------------------------------------------------\n",
    "print(\"Training gender classifier…\")\n",
    "gender_clf.fit(X, gender_y)\n",
    "\n",
    "print(\"Training ethnicity classifier…\")\n",
    "ethnicity_clf.fit(X, ethnicity_y)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# SAVE\n",
    "# ------------------------------------------------------------\n",
    "OUT_DIR = \"src/models\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "gender_path    = os.path.join(OUT_DIR, \"gender_clf.pkl\")\n",
    "ethnicity_path = os.path.join(OUT_DIR, \"ethnicity_clf.pkl\")\n",
    "\n",
    "joblib.dump(gender_clf, gender_path)\n",
    "joblib.dump(ethnicity_clf, ethnicity_path)\n",
    "\n",
    "print(\"\\nSaved models:\")\n",
    "print(\"  →\", gender_path)\n",
    "print(\"  →\", ethnicity_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca0051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: (31396, 2)\n",
      "Attributes: (31396, 4)\n",
      "shape: (5, 3)\n",
      "┌───────────────────────┬─────────────┬────────────────┐\n",
      "│ filename              ┆ gender_pred ┆ ethnicity_pred │\n",
      "│ ---                   ┆ ---         ┆ ---            │\n",
      "│ str                   ┆ str         ┆ str            │\n",
      "╞═══════════════════════╪═════════════╪════════════════╡\n",
      "│ SFHQ_pt4_00000001.jpg ┆ unknown     ┆ unknown        │\n",
      "│ SFHQ_pt4_00000002.jpg ┆ unknown     ┆ unknown        │\n",
      "│ SFHQ_pt4_00000003.jpg ┆ unknown     ┆ unknown        │\n",
      "│ SFHQ_pt4_00000004.jpg ┆ male        ┆ unknown        │\n",
      "│ SFHQ_pt4_00000005.jpg ┆ male        ┆ unknown        │\n",
      "└───────────────────────┴─────────────┴────────────────┘\n",
      "\n",
      "Final merged shape: (31396, 7)\n",
      "\n",
      "Saved final attribute table → data/processed/metadata/attributes_with_predictions.parquet\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Step 9 — Apply Gender & Ethnicity Classifiers to All Embeddings\n",
    "# ================================================================\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load embeddings + existing attributes\n",
    "# ----------------------------------------------------------\n",
    "emb = pl.read_parquet(\"data/processed/embeddings/embeddings_clip.parquet\")\n",
    "attr = pl.read_parquet(\"data/processed/metadata/attributes.parquet\")\n",
    "\n",
    "print(\"Embeddings:\", emb.shape)\n",
    "print(\"Attributes:\", attr.shape)\n",
    "\n",
    "# Merge\n",
    "df = (\n",
    "    emb\n",
    "    .join(attr, on=\"filename\", how=\"inner\")\n",
    ")\n",
    "\n",
    "# Convert embeddings → numpy matrix\n",
    "X = np.vstack(df[\"embedding\"].to_list())\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load trained classifiers\n",
    "# ----------------------------------------------------------\n",
    "gender_clf = joblib.load(\"src/models/gender_clf.pkl\")\n",
    "ethnicity_clf = joblib.load(\"src/models/ethnicity_clf.pkl\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Run predictions\n",
    "# ----------------------------------------------------------\n",
    "gender_pred = gender_clf.predict(X)\n",
    "ethnicity_pred = ethnicity_clf.predict(X)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Build prediction table\n",
    "# ----------------------------------------------------------\n",
    "df_pred = pl.DataFrame({\n",
    "    \"filename\": df[\"filename\"],\n",
    "    \"gender_pred\": gender_pred,\n",
    "    \"ethnicity_pred\": ethnicity_pred,\n",
    "})\n",
    "\n",
    "print(df_pred.head())\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Merge with original attributes\n",
    "# ----------------------------------------------------------\n",
    "full = (\n",
    "    df\n",
    "    .join(df_pred, on=\"filename\", how=\"inner\")\n",
    ")\n",
    "\n",
    "print(\"\\nFinal merged shape:\", full.shape)\n",
    "full.head()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Save final table\n",
    "# ----------------------------------------------------------\n",
    "OUT = \"data/processed/metadata/attributes_with_predictions.parquet\"\n",
    "full.write_parquet(OUT)\n",
    "\n",
    "print(\"\\nSaved final attribute table →\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fd1ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file → src/attributes/face_attributes.py\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# ============================================================\n",
    "# Step 10 — Update face_attributes.py with new classifier logic\n",
    "# ============================================================\n",
    "\n",
    "updated_code = r\"\"\"\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load trained models\n",
    "# ------------------------------------------------------------\n",
    "MODEL_DIR = os.path.join(os.path.dirname(__file__), \"..\", \"models\")\n",
    "MODEL_DIR = os.path.abspath(MODEL_DIR)\n",
    "\n",
    "GENDER_MODEL = joblib.load(os.path.join(MODEL_DIR, \"gender_clf.pkl\"))\n",
    "ETHNICITY_MODEL = joblib.load(os.path.join(MODEL_DIR, \"ethnicity_clf.pkl\"))\n",
    "\n",
    "# Mapping (must match training order)\n",
    "GENDER_CLASSES = [\"female\", \"male\"]\n",
    "ETHNICITY_CLASSES = [\n",
    "    \"white\",\n",
    "    \"black\",\n",
    "    \"latino/hispanic\",\n",
    "    \"east_or_southeast_asian\",\n",
    "    \"indian\",\n",
    "    \"middle_eastern\"\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Extract CLIP embedding for a single image\n",
    "# (Used at inference time on new images)\n",
    "# ------------------------------------------------------------\n",
    "def get_embedding(image_path):\n",
    "    from src.embeddings.embed_clip import get_clip_embedding\n",
    "    return get_clip_embedding(image_path)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main inference function used by pipelines\n",
    "# ------------------------------------------------------------\n",
    "def infer_attributes(image_path):\n",
    "    emb = get_embedding(image_path)          # shape (N,)\n",
    "    emb = np.array(emb).reshape(1, -1)\n",
    "\n",
    "    gender_pred = GENDER_MODEL.predict(emb)[0]\n",
    "    ethnicity_pred = ETHNICITY_MODEL.predict(emb)[0]\n",
    "\n",
    "    return {\n",
    "        \"gender\": GENDER_CLASSES[gender_pred],\n",
    "        \"ethnicity\": ETHNICITY_CLASSES[ethnicity_pred],\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Write the updated file\n",
    "ATTR_PATH = \"src/attributes/face_attributes.py\"\n",
    "\n",
    "with open(ATTR_PATH, \"w\") as f:\n",
    "    f.write(updated_code)\n",
    "\n",
    "print(f\"Updated file → {ATTR_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99fc0dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing images: ['SFHQ_pt4_00118863.jpg', 'SFHQ_pt4_00090181.jpg', 'SFHQ_pt4_00001212.jpg', 'SFHQ_pt4_00008602.jpg', 'SFHQ_pt4_00052398.jpg'] \n",
      "\n",
      "--- SFHQ_pt4_00118863.jpg ---\n",
      "Gender:     unknown\n",
      "Ethnicity:  unknown\n",
      "\n",
      "--- SFHQ_pt4_00090181.jpg ---\n",
      "Gender:     unknown\n",
      "Ethnicity:  white\n",
      "\n",
      "--- SFHQ_pt4_00001212.jpg ---\n",
      "Gender:     male\n",
      "Ethnicity:  black\n",
      "\n",
      "--- SFHQ_pt4_00008602.jpg ---\n",
      "Gender:     unknown\n",
      "Ethnicity:  unknown\n",
      "\n",
      "--- SFHQ_pt4_00052398.jpg ---\n",
      "Gender:     male\n",
      "Ethnicity:  unknown\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import src.attributes.face_attributes as fa  # use the src path so imports work consistently\n",
    "\n",
    "IMG_DIR = \"data/processed/preproc\"\n",
    "\n",
    "def infer_attributes_safe(image_path):\n",
    "    emb = fa.get_embedding(image_path)\n",
    "    emb = np.array(emb).reshape(1, -1)\n",
    "\n",
    "    gender_pred = fa.GENDER_MODEL.predict(emb)[0]\n",
    "    ethnicity_pred = fa.ETHNICITY_MODEL.predict(emb)[0]\n",
    "\n",
    "    def resolve(pred, classes):\n",
    "        if isinstance(pred, (int, np.integer)):\n",
    "            return classes[pred]\n",
    "        return str(pred)\n",
    "\n",
    "    return {\n",
    "        \"gender\": resolve(gender_pred, fa.GENDER_CLASSES),\n",
    "        \"ethnicity\": resolve(ethnicity_pred, fa.ETHNICITY_CLASSES),\n",
    "    }\n",
    "\n",
    "# pick 5 random images\n",
    "sample_files = random.sample(\n",
    "    [f for f in os.listdir(IMG_DIR) if f.lower().endswith(\".jpg\")],\n",
    "    5\n",
    ")\n",
    "\n",
    "print(\"Testing images:\", sample_files, \"\\n\")\n",
    "\n",
    "results = []\n",
    "for fname in sample_files:\n",
    "    path = os.path.join(IMG_DIR, fname)\n",
    "    attrs = infer_attributes_safe(path)\n",
    "    results.append((fname, attrs))\n",
    "\n",
    "# Display results\n",
    "for fname, attrs in results:\n",
    "    print(f\"--- {fname} ---\")\n",
    "    print(\"Gender:    \", attrs[\"gender\"])\n",
    "    print(\"Ethnicity: \", attrs[\"ethnicity\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6f0d7",
   "metadata": {},
   "source": [
    "### Step 13 — Batch Inference for All Images (Full Dataset)\n",
    "\n",
    "This step applies our trained gender & ethnicity classifiers to **all embeddings**, merges manual labels, and produces the final clean attribute table.\n",
    "\n",
    "- Loads embeddings  \n",
    "- Loads raw attributes  \n",
    "- Loads manual labels  \n",
    "- Applies classifiers  \n",
    "- Merges everything together  \n",
    "- Saves `attributes_final.parquet`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88adf152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: (31396, 2)\n",
      "Attributes: (31396, 4)\n",
      "Manual: (200, 3)\n",
      "\n",
      "Saved final full attribute table → data/processed/metadata/attributes_final.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>filename</th><th>age</th><th>gender_final</th><th>ethnicity_final</th></tr><tr><td>str</td><td>null</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;SFHQ_pt4_00034620.jpg&quot;</td><td>null</td><td>&quot;female&quot;</td><td>&quot;white&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00107598.jpg&quot;</td><td>null</td><td>&quot;unknown&quot;</td><td>&quot;white&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00072675.jpg&quot;</td><td>null</td><td>&quot;unknown&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00086092.jpg&quot;</td><td>null</td><td>&quot;unknown&quot;</td><td>&quot;unknown&quot;</td></tr><tr><td>&quot;SFHQ_pt4_00065309.jpg&quot;</td><td>null</td><td>&quot;female&quot;</td><td>&quot;unknown&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────────────────┬──────┬──────────────┬─────────────────┐\n",
       "│ filename              ┆ age  ┆ gender_final ┆ ethnicity_final │\n",
       "│ ---                   ┆ ---  ┆ ---          ┆ ---             │\n",
       "│ str                   ┆ null ┆ str          ┆ str             │\n",
       "╞═══════════════════════╪══════╪══════════════╪═════════════════╡\n",
       "│ SFHQ_pt4_00034620.jpg ┆ null ┆ female       ┆ white           │\n",
       "│ SFHQ_pt4_00107598.jpg ┆ null ┆ unknown      ┆ white           │\n",
       "│ SFHQ_pt4_00072675.jpg ┆ null ┆ unknown      ┆ unknown         │\n",
       "│ SFHQ_pt4_00086092.jpg ┆ null ┆ unknown      ┆ unknown         │\n",
       "│ SFHQ_pt4_00065309.jpg ┆ null ┆ female       ┆ unknown         │\n",
       "└───────────────────────┴──────┴──────────────┴─────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Paths\n",
    "# --------------------------------------------------\n",
    "EMB = \"data/processed/embeddings/embeddings_clip.parquet\"\n",
    "ATTR = \"data/processed/metadata/attributes.parquet\"\n",
    "MANUAL = \"data/processed/metadata/manual_labels.csv\"\n",
    "OUT = \"data/processed/metadata/attributes_final.parquet\"\n",
    "\n",
    "GENDER_MODEL = \"src/models/gender_clf.pkl\"\n",
    "ETH_MODEL = \"src/models/ethnicity_clf.pkl\"\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load models\n",
    "# --------------------------------------------------\n",
    "gender_clf = joblib.load(GENDER_MODEL)\n",
    "ethnicity_clf = joblib.load(ETH_MODEL)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load data\n",
    "# --------------------------------------------------\n",
    "df_emb = pl.read_parquet(EMB)\n",
    "df_attr = pl.read_parquet(ATTR)\n",
    "df_manual = pl.read_csv(MANUAL) if os.path.exists(MANUAL) else pl.DataFrame()\n",
    "\n",
    "print(\"Embeddings:\", df_emb.shape)\n",
    "print(\"Attributes:\", df_attr.shape)\n",
    "print(\"Manual:\", df_manual.shape)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Prepare classifier input\n",
    "# --------------------------------------------------\n",
    "X = np.vstack(df_emb[\"embedding\"].to_list())\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Predict\n",
    "# --------------------------------------------------\n",
    "gender_pred = gender_clf.predict(X)\n",
    "eth_pred = ethnicity_clf.predict(X)\n",
    "\n",
    "df_pred = pl.DataFrame({\n",
    "    \"filename\": df_emb[\"filename\"],\n",
    "    \"gender_pred\": gender_pred,\n",
    "    \"ethnicity_pred\": eth_pred,\n",
    "})\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Merge everything\n",
    "# --------------------------------------------------\n",
    "merged = (\n",
    "    df_attr\n",
    "    .join(df_pred, on=\"filename\", how=\"inner\")\n",
    ")\n",
    "\n",
    "if df_manual.height > 0:\n",
    "    merged = (\n",
    "        merged\n",
    "        .join(df_manual, on=\"filename\", how=\"left\", suffix=\"_manual\")\n",
    "    )\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Final label logic:\n",
    "# 1. manual label > model prediction > original > unknown\n",
    "# --------------------------------------------------\n",
    "merged = merged.with_columns([\n",
    "    pl.coalesce([\"gender_manual\", \"gender_pred\", \"gender\", pl.lit(\"unknown\")])\n",
    "      .alias(\"gender_final\"),\n",
    "\n",
    "    pl.coalesce([\"ethnicity_manual\", \"ethnicity_pred\", \"ethnicity\", pl.lit(\"unknown\")])\n",
    "      .alias(\"ethnicity_final\"),\n",
    "])\n",
    "\n",
    "# Keep only useful columns\n",
    "final = merged.select([\n",
    "    \"filename\",\n",
    "    \"age\",\n",
    "    \"gender_final\",\n",
    "    \"ethnicity_final\",\n",
    "])\n",
    "\n",
    "final.write_parquet(OUT)\n",
    "\n",
    "print(\"\\nSaved final full attribute table →\", OUT)\n",
    "final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37d9ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a075e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading attributes_final…\n",
      "(31396, 4)\n",
      "Loading attractiveness_scores…\n",
      "(700, 2)\n",
      "After merge: (31396, 5)\n",
      "shape: (5, 5)\n",
      "┌───────────────────────┬──────┬──────────────┬─────────────────┬────────────────┐\n",
      "│ filename              ┆ age  ┆ gender_final ┆ ethnicity_final ┆ attractiveness │\n",
      "│ ---                   ┆ ---  ┆ ---          ┆ ---             ┆ ---            │\n",
      "│ str                   ┆ null ┆ str          ┆ str             ┆ f32            │\n",
      "╞═══════════════════════╪══════╪══════════════╪═════════════════╪════════════════╡\n",
      "│ SFHQ_pt4_00034620.jpg ┆ null ┆ female       ┆ white           ┆ null           │\n",
      "│ SFHQ_pt4_00107598.jpg ┆ null ┆ unknown      ┆ white           ┆ null           │\n",
      "│ SFHQ_pt4_00072675.jpg ┆ null ┆ unknown      ┆ unknown         ┆ null           │\n",
      "│ SFHQ_pt4_00086092.jpg ┆ null ┆ unknown      ┆ unknown         ┆ null           │\n",
      "│ SFHQ_pt4_00065309.jpg ┆ null ┆ female       ┆ unknown         ┆ null           │\n",
      "└───────────────────────┴──────┴──────────────┴─────────────────┴────────────────┘\n",
      "✔ Saved merged file → data/processed/metadata/attributes_final.parquet\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# Merge attractiveness scores into attributes_final.parquet\n",
    "# =============================================================\n",
    "\n",
    "import polars as pl\n",
    "import os\n",
    "\n",
    "ATTR_FINAL = \"data/processed/metadata/attributes_final.parquet\"\n",
    "ATTR_SCORES = \"data/processed/metadata/attractiveness_scores.parquet\"\n",
    "OUT_PATH = \"data/processed/metadata/attributes_final.parquet\"   # overwrite same file\n",
    "\n",
    "print(\"Loading attributes_final…\")\n",
    "df_attr = pl.read_parquet(ATTR_FINAL)\n",
    "print(df_attr.shape)\n",
    "\n",
    "print(\"Loading attractiveness_scores…\")\n",
    "df_scores = pl.read_parquet(ATTR_SCORES)\n",
    "print(df_scores.shape)\n",
    "\n",
    "# Ensure consistency\n",
    "if \"score\" in df_scores.columns:\n",
    "    df_scores = df_scores.rename({\"score\": \"attractiveness\"})\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Merge: left join on filename\n",
    "# -------------------------------------------------------------\n",
    "df_merged = (\n",
    "    df_attr\n",
    "    .join(df_scores, on=\"filename\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"After merge:\", df_merged.shape)\n",
    "\n",
    "# Safety check\n",
    "print(df_merged.head(5))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Save merged output back to attributes_final.parquet\n",
    "# -------------------------------------------------------------\n",
    "df_merged.write_parquet(OUT_PATH)\n",
    "\n",
    "print(\"✔ Saved merged file →\", OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7b9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facestats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
