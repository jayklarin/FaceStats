{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8462c7e4",
   "metadata": {},
   "source": [
    "# Tools Used in Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc8d8e",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "%% =============================\n",
    "%% PREPROCESSING\n",
    "%% =============================\n",
    "subgraph PRE[\"ğŸ› ï¸ Preprocessing Tools\"]\n",
    "    MP[\"âš™ï¸ Mediapipe FaceMesh<br>(face alignment)\"]\n",
    "    CV2[\"âš™ï¸ OpenCV<br>(resizing, cropping)\"]\n",
    "    PIL[\"ğŸ–¼ï¸ Pillow<br>(image I/O)\"]\n",
    "    TQDM[\"tqdm<br>(progress bars)\"]\n",
    "end\n",
    "\n",
    "%% =============================\n",
    "%% EMBEDDINGS\n",
    "%% =============================\n",
    "subgraph EMB[\"ğŸ§  Embedding Extraction\"]\n",
    "    HF[\"ğŸ¤— HuggingFace Transformers<br>(CLIP ViT-H/14)\"]\n",
    "    NP[\"numpy<br>(matrix ops)\"]\n",
    "    PKL[\"pickle<br>(pretrained embeddings)\"]\n",
    "end\n",
    "\n",
    "%% =============================\n",
    "%% ML MODELS\n",
    "%% =============================\n",
    "subgraph ML[\"ğŸ§  ML & Regression Models\"]\n",
    "    TORCH[\"torch<br>(MLP regressor)\"]\n",
    "    SKL[\"scikit-learn<br>(PCA, metrics)\"]\n",
    "end\n",
    "\n",
    "%% =============================\n",
    "%% DATA ENGINEERING\n",
    "%% =============================\n",
    "subgraph DATA[\"ğŸ“Š Data Handling & Metadata\"]\n",
    "    PANDAS[\"pandas<br>(analytics, merging)\"]\n",
    "    JSON[\"json<br>(index files, metadata)\"]\n",
    "    PARQ[\"Parquet / Polars<br>(structured data)\"]\n",
    "end\n",
    "\n",
    "%% =============================\n",
    "%% VISUALIZATION\n",
    "%% =============================\n",
    "subgraph VIS[\"ğŸ“ˆ Visualization\"]\n",
    "    MPL[\"matplotlib<br>(composite grids)\"]\n",
    "    ST[\"streamlit<br>(future app UI)\"]\n",
    "end\n",
    "\n",
    "%% =============================\n",
    "%% FUTURE / PLANNED\n",
    "%% =============================\n",
    "subgraph FUTURE[\"ğŸš€ Planned Tools\"]\n",
    "    POLARS[\"ğŸ“ Polars<br>(fast dataframe ops)\"]\n",
    "    ONNX[\"ğŸ”§ ONNX Runtime<br>(optional accel)\"]\n",
    "    OPENCLIP[\"ğŸ§  open_clip<br>(alt CLIP model)\"]\n",
    "    LGBM[\"ğŸŒ² LightGBM<br>(alt regressor)\"]\n",
    "    HF_SPACE[\"ğŸ¤— HF Spaces<br>(hosting)\"]\n",
    "end\n",
    "\n",
    "%% =============================\n",
    "%% CONNECTIONS (LANDSCAPE)\n",
    "%% =============================\n",
    "\n",
    "PRE --> EMB --> ML --> VIS\n",
    "EMB --> DATA\n",
    "DATA --> ML\n",
    "\n",
    "PANDAS --> ML\n",
    "NP --> TORCH\n",
    "JSON --> DATA\n",
    "PKL --> EMB\n",
    "\n",
    "FUTURE --> ML\n",
    "FUTURE --> DATA\n",
    "FUTURE --> EMB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb508e3",
   "metadata": {},
   "source": [
    "# ğŸ› ï¸ Diagram 1 - FaceStats v4.0 High Level Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa36c1",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "A[\"ğŸ“ Raw Images<br>data/raw/<br><code>preprocess.py</code>\"] \n",
    "    --> B[\"ğŸ–¼ï¸ Preprocessing<br>PIL Resize 512Ã—512<br>No OpenCV Needed<br><code>preprocess.py</code>\"]\n",
    "\n",
    "B --> C[\"ğŸ§  Embedding Extraction<br>HuggingFace CLIP / ViT<br>transformers + torch<br><code>embedding_extractor.py</code>\"]\n",
    "\n",
    "C --> D[\"ğŸ‘¥ Attribute Models<br>Age / Gender / Ethnicity<br>HuggingFace pipelines<br><code>attribute_inference.py</code>\"]\n",
    "\n",
    "C --> E[\"ğŸ’š Attractiveness Regressor<br>PyTorch MLP<br><code>attractiveness_model.py</code>\"]\n",
    "\n",
    "D --> F[\"ğŸ“Š Metadata Table Builder<br>Polars / Parquet<br><code>metadata_builder.py</code>\"]\n",
    "\n",
    "E --> F\n",
    "\n",
    "F --> G[\"ğŸ§¬ Composite Generator<br>PIL + NumPy Weighted Mean<br><code>composite_generator.py</code>\"]\n",
    "\n",
    "G --> H[\"ğŸ“ˆ Dashboards<br>Streamlit + Matplotlib<br><code>app.py</code>\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1332b1e",
   "metadata": {},
   "source": [
    "# ğŸ–¼ï¸ Diagram 2 â€” Preprocessing Flow\n",
    "*Shows exactly how images are normalized and resized.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a37722",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "A[\"ğŸ“ Input Images<br>data/raw/\"] \n",
    "    --> B[\"ğŸ” File Loader<br>PIL Image.open<br><code>preprocess.py</code>\"]\n",
    "\n",
    "B --> C[\"ğŸ§½ Clean / Normalize<br>Convert to RGB<br><code>PIL</code>\"]\n",
    "\n",
    "C --> D[\"ğŸ“ Resize 512Ã—512<br>High-quality bicubic<br><code>PIL.Image.resize</code>\"]\n",
    "\n",
    "D --> E[\"ğŸ’¾ Save JPEG<br>data/processed/preproc/<br><code>preprocess.py</code>\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5733be",
   "metadata": {},
   "source": [
    "# ğŸ§  Diagram 3 â€” Embedding Extraction\n",
    "*Uses HuggingFace, zero OpenCV/ONNX.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f8875",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "A[\"ğŸ–¼ï¸ Preprocessed Images<br>data/processed/preproc/\"] \n",
    "    --> B[\"ğŸ“¥ Tokenizer<br>CLIPProcessor<br><code>transformers</code>\"]\n",
    "\n",
    "B --> C[\"ğŸ§  Forward Pass<br>CLIPModel or ViTModel<br>torch + transformers<br><code>embedding_extractor.py</code>\"]\n",
    "\n",
    "C --> D[\"ğŸ“ L2 Normalize<br>512-D vector<br><code>NumPy / Torch</code>\"]\n",
    "\n",
    "D --> E[\"ğŸ’¾ Store Embeddings<br>embeddings.parquet<br><code>polars</code>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e2c1e6",
   "metadata": {},
   "source": [
    "# ğŸ‘¥ Diagram 4 â€” Attribute Models\n",
    "*No ONNX â€” pure HF pipelines.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799565be",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "A[\"ğŸ§  Embeddings + Images\"] \n",
    "    --> B[\"ğŸ‘¤ HF Age Model<br>AutoModelForImageClassification<br><code>attribute_inference.py</code>\"]\n",
    "\n",
    "A --> C[\"ğŸ‘¥ HF Gender Model<br>transformers pipeline\"]\n",
    "\n",
    "A --> D[\"ğŸŒ HF Ethnicity Model<br>image-classification model\"]\n",
    "\n",
    "B --> E[\"ğŸ“„ Attributes Table<br>attributes.parquet\"]\n",
    "C --> E\n",
    "D --> E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea5c2c8",
   "metadata": {},
   "source": [
    "# ğŸ’š Diagram 5 â€” Attractiveness Model\n",
    "*Your in-house regression model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f7391",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "A[\"ğŸ”¢ Embeddings (512-D)\"] \n",
    "    --> B[\"ğŸ§  PyTorch MLP Regressor<br>torch.nn.Sequential<br><code>attractiveness_model.py</code>\"]\n",
    "\n",
    "B --> C[\"ğŸ“ˆ Score Output<br>scores.parquet\"]\n",
    "\n",
    "C --> D[\"ğŸ“¦ Merge into Metadata<br><code>metadata_builder.py</code>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12871a29",
   "metadata": {},
   "source": [
    "# ğŸ“Š Diagram 6 â€” Metadata Table Builder\n",
    "*Combines embeddings, attributes, scores into one dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554c4c6",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "A[\"ğŸ”¢ Embeddings.parquet\"] \n",
    "    --> E[\"ğŸ“Š Merge Tables<br>Polars DataFrame<br><code>metadata_builder.py</code>\"]\n",
    "\n",
    "B[\"ğŸ‘¤ Attributes.parquet\"] --> E\n",
    "C[\"ğŸ’š Scores.parquet\"] --> E\n",
    "\n",
    "E --> F[\"ğŸ’¾ Master Table<br>master.parquet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753e106c",
   "metadata": {},
   "source": [
    "# ğŸ§¬ Diagram 7 â€” Composite Image Pipeline\n",
    "*Produces PCA or weighted-mean faces.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe39e0",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "\n",
    "A[\"ğŸ“Š Master Metadata<br>master.parquet\"] \n",
    "    --> B[\"ğŸ“‹ Filter Selection<br>age, gender, attractiveness, ethnicity<br><code>composite_generator.py</code>\"]\n",
    "\n",
    "B --> C[\"ğŸ“¥ Load Images<br>PIL image loader\"]\n",
    "\n",
    "C --> D[\"â• NumPy Stack<br>Convert to arrays<br><code>numpy</code>\"]\n",
    "\n",
    "D --> E[\"ğŸ“Š Mean / Weighted Mean<br>PCA optional<br><code>NumPy / sklearn PCA</code>\"]\n",
    "\n",
    "E --> F[\"ğŸ–¼ï¸ Save Composite<br>data/processed/composites/<br><code>composite_generator.py</code>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c6844",
   "metadata": {},
   "source": [
    "# ğŸ“¦ Idealized Repository Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42c339",
   "metadata": {},
   "source": [
    "```text\n",
    "FaceStats/\n",
    "â”œâ”€â”€ LICENSE\n",
    "â”œâ”€â”€ README.md\n",
    "â”œâ”€â”€ requirements.txt\n",
    "â”œâ”€â”€ schematics.ipynb\n",
    "â”œâ”€â”€ x.ipynb\n",
    "\n",
    "â”œâ”€â”€ config/\n",
    "â”‚   â””â”€â”€ ...                               # Configuration files\n",
    "\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ attributes/\n",
    "â”‚   â”œâ”€â”€ embeddings/\n",
    "â”‚   â”œâ”€â”€ interim/\n",
    "â”‚   â”‚   â””â”€â”€ checkpoints/\n",
    "â”‚   â”œâ”€â”€ preprocessed/\n",
    "â”‚   â”œâ”€â”€ processed/\n",
    "â”‚   â”‚   â”œâ”€â”€ metadata/\n",
    "â”‚   â”‚   â”œâ”€â”€ attributes_clean.parquet\n",
    "â”‚   â”‚   â”œâ”€â”€ attributes_flags.parquet\n",
    "â”‚   â”‚   â”œâ”€â”€ attributes_with_clusters.parquet\n",
    "â”‚   â”‚   â”œâ”€â”€ attributes_with_meta.parquet\n",
    "â”‚   â”‚   â”œâ”€â”€ attributes.parquet\n",
    "â”‚   â”‚   â””â”€â”€ embeddings_clip.parquet\n",
    "â”‚   â”œâ”€â”€ raw/\n",
    "â”‚   â”‚   â”œâ”€â”€ a small sample (700 images)/\n",
    "â”‚   â”‚   â”œâ”€â”€ SFHQ_pt4_00000xxx.jpgâ€¦\n",
    "â”‚   â””â”€â”€ # TODO: data/raw/part1, part2, part3, part4 (full dataset)\n",
    "\n",
    "â”œâ”€â”€ models_insightface/\n",
    "â”‚   â””â”€â”€ ...                               # InsightFace model weights, configs\n",
    "\n",
    "â”œâ”€â”€ notebooks/\n",
    "â”‚   â”œâ”€â”€ 01_preprocess.ipynb\n",
    "â”‚   â”œâ”€â”€ 02_embeddings.ipynb\n",
    "â”‚   â”œâ”€â”€ 03_attributes.ipynb\n",
    "â”‚   â”œâ”€â”€ 03_labels.ipynb\n",
    "â”‚   â”œâ”€â”€ 04_visualize_attributes.ipynb\n",
    "â”‚   â”œâ”€â”€ 05_ethnicity_clusters.ipynb\n",
    "â”‚   â””â”€â”€ # TODO: fs07_age_gender_ethnicity_inference.ipynb\n",
    "â”‚   â””â”€â”€ # TODO: fs08_fairface_alignment.ipynb\n",
    "\n",
    "â”œâ”€â”€ src/\n",
    "â”‚   â”œâ”€â”€ attributes/\n",
    "â”‚   â”‚   â”œâ”€â”€ age_infer.py\n",
    "â”‚   â”‚   â”œâ”€â”€ face_attributes.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: ethnicity_infer.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: gender_infer.py\n",
    "\n",
    "â”‚   â”œâ”€â”€ composite/\n",
    "â”‚   â”‚   â”œâ”€â”€ composite_generator.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: composite_filters.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: composite_explorer.py\n",
    "\n",
    "â”‚   â”œâ”€â”€ data_utils/\n",
    "â”‚   â”‚   â”œâ”€â”€ constants.py\n",
    "â”‚   â”‚   â”œâ”€â”€ filters.py\n",
    "â”‚   â”‚   â”œâ”€â”€ io_utils.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: dataset_splits.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: data_validation.py\n",
    "\n",
    "â”‚   â”œâ”€â”€ embeddings/\n",
    "â”‚   â”‚   â”œâ”€â”€ embed_clip.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: embed_openclip.py   # Only if needed\n",
    "\n",
    "â”‚   â”œâ”€â”€ learning/\n",
    "â”‚   â”‚   â”œâ”€â”€ learning_curves.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: trainers.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: loss_functions.py\n",
    "\n",
    "â”‚   â”œâ”€â”€ metadata/\n",
    "â”‚   â”‚   â””â”€â”€ build_master.py\n",
    "\n",
    "â”‚   â”œâ”€â”€ models/\n",
    "â”‚   â”‚   â”œâ”€â”€ attractiveness_model.py\n",
    "â”‚   â”‚   â”œâ”€â”€ train_attractiveness.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: multi_attribute_model.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: fairness_model.py\n",
    "\n",
    "â”‚   â”œâ”€â”€ pipeline/\n",
    "â”‚   â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”‚   â”œâ”€â”€ preprocess.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: full_pipeline_runner.py\n",
    "\n",
    "â”‚   â”œâ”€â”€ visualization/\n",
    "â”‚   â”‚   â”œâ”€â”€ app.py\n",
    "â”‚   â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”‚   â””â”€â”€ # TODO: dashboards/\n",
    "â”‚   â”‚       â””â”€â”€ # TODO: attractiveness_dashboard.py\n",
    "â”‚   â”‚       â””â”€â”€ # TODO: embeddings_explorer.py\n",
    "â”‚   â”‚       â””â”€â”€ # TODO: composite_gallery.py\n",
    "\n",
    "â”‚   â””â”€â”€ # TODO: utils/\n",
    "â”‚       â””â”€â”€ # TODO: logger.py\n",
    "â”‚       â””â”€â”€ # TODO: config_loader.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45f7c3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facestats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
